{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "12M_Interpretowalne_ML_CAM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNDQCDSFVdQ4"
      },
      "source": [
        "# **Metody interpretowalności dla sieci neuronowych**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seqEdVR1VdQ7"
      },
      "source": [
        "## Wprowadzenie\n",
        "Ogólna zasada jest taka, że im bardziej skomplikowana sieć (model), tym bardziej złożone problemy potrafi opisać (co jest dość intuicyjne). Wiąże się z tym pewna komplikacja w postaci utraty interpretowalności wraz ze wzrastającym poziomem złożoności modelu.\n",
        "\n",
        "### Po co w ogóle się przejmować interpretowalnością?\n",
        "\n",
        "* ulepszanie modelu -> gdy przeanalizujemy na co zwraca uwagę podczas klasyfikacji i regresji, i dowiemy się, że skupia się na niezbyt istotnej cesze, możemy spróbować ulepszyć model. Przykład: **[obraz](http://3.bp.blogspot.com/-S8g8SNWhyR0/WIsOFqPD2WI/AAAAAAAAA68/9yNFp6sdao0Er7qDIqEPu7ORTU589tFCACK4B/s1600/Bildschirmfoto%2B2017-01-27%2Bum%2B10.08.11.png): pies husky na śniegu => predykcja: wilk**\n",
        "\n",
        "\n",
        "* powody etyczne: zapobieganie dyskryminacji wdrukowanej przez człowieka opisującego dane treningowe oraz modele stosowane do celów medycznych\n",
        "* powody prawne: od maja 2019 r. każdy obywatel Unii ma prawo poznać rozumowanie stojące za każdą zautomatyzowaną, dotyczącą go decyzją\n",
        "* jedyny sposób, żeby uczenie maszynowe nauczyło nas czegoś nowego o fizyce?\n",
        "\n",
        "Przykłady interpretowalnych modeli, które poznaliśmy na zajęciach: regresja logistyczna, drzewa decyzyjne, do pewnego stopnia maszyny wektorów wspierających\n",
        "\n",
        "Sztandarowym przykładem bogatego modelu nieinterpretowalnego są głębokie sieci neuronowe (w tym konwolucyjne, szczególnie skuteczne w analizie obrazków)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFpUrBiRgFiV"
      },
      "source": [
        "## Jakie mamy metody?\n",
        "\n",
        "Baaaaaardzo dużo. W ogólności można je podzielić na trzy kategorie (choć nie wyczerpuje to tematu! Dziedzina interpretowalnego uczenia maszynowego produkuje kilka nowych metod co tydzień!).\n",
        "\n",
        "Można zadać sobie następujące pytania:\n",
        "1. Jaki input, jakie dane wejściowe maksymalnie aktywują neuron odpowiadający predykcji konkretnej klasy? Czyli jak wygląda według modelu archetypowy pies/kot/dziewiątka? Przykłady: [wizualizacja cech (feature visualisation)](https://storage.googleapis.com/lucid-static/feature-visualization/4.png), zainteresowani mogą wygooglować DeepDream\n",
        "2. Czy możemy lokalnie zastąpić ten model prostszym, za to interpretowalnym? Przykłady: [LIME](https://towardsdatascience.com/understanding-model-predictions-with-lime-a582fdff3a3b).\n",
        "3. Która część danych wejściowych (np. która część obrazka) była najbardziej odpowiedzialna za daną predykcję? Przykłady: [mapy ciepła](https://towardsdatascience.com/demystifying-convolutional-neural-networks-using-class-activation-maps-fe94eda4cef1)\n",
        "\n",
        "Część takich metod jest zebrana w ładnych bibliotekach np. [iNNvestigate](https://github.com/albermax/innvestigate/blob/master/examples/notebooks/mnist_compare_methods.ipynb) lub [Alibi](https://github.com/SeldonIO/alibi).\n",
        "\n",
        "\n",
        "W ramach dzisiejszych ćwiczeń poznamy i pobawimy się podstawową metodą interpretowalności z kategorii 3, czyli mapami aktywacji klasy (CAM, Class Activation Maps, [publikacja](https://arxiv.org/pdf/1512.04150.pdf)). Mają wiele pochodnych i udoskonaleń (np. [Grad-CAM](https://jacobgil.github.io/deeplearning/class-activation-maps)), zbiorczo takie mapy nazywa się czasem mapami ciepła."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K42wAvdfOML"
      },
      "source": [
        "# Class Activation Maps (CAM)\n",
        "\n",
        "Kod bazuje na [kodzie stworzonym przez autorów metody](https://github.com/zhoubolei/CAM)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEkPKbxiWWu-"
      },
      "source": [
        "![CAM](https://drive.google.com/uc?id=1vibsld9iq7j4GYgDP5LMXdoitvfr8q_M)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ows63OwwMZ8i"
      },
      "source": [
        "## Zaczniemy od importu wytrenowanej i skomplikowanej sieci **z GAP na końcu**\n",
        "\n",
        "Żeby było więcej zabawy, będziemy dzisiaj sprawdzać mapy ciepła na obrazkach ze zbioru ImageNet. To zbiór ponad 14 milionów zdjęć z [1000](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a) kategorii (a dokładniej z 1000 nienachodzących na siebie kategorii, generalnie wylicza się tam 20 000 kategorii, ale wyścigi sieci neuronowych robi się na tych rozłącznych).\n",
        "\n",
        "Zaprojektowanie od zera skutecznej sieci rozpoznającej tyle obiektów byłoby trudne i czasochłonne (głównie czasochłonne), więc stańmy na ramionach olbrzymów :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpfU-WXKg5CY"
      },
      "source": [
        "import io\n",
        "import requests\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "from torchvision import models, transforms\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_rTipdKigUa"
      },
      "source": [
        "# obrazek do analizy\n",
        "LABELS_URL = 'https://s3.amazonaws.com/outcome-blog/imagenet/labels.json'\n",
        "IMG_URL = 'http://media.mlive.com/news_impact/photo/9933031-large.jpg'\n",
        "\n",
        "# wydrukuj obrazek\n",
        "response = requests.get(IMG_URL)\n",
        "img_pil = Image.open(io.BytesIO(response.content))\n",
        "plt.imshow(img_pil)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MiOF7PKbZIj"
      },
      "source": [
        "# Jeśli chcesz zapisywać wyniki, potrzebujesz podłączyć dysk Google'a\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "folder = '/content/drive/My Drive/Colab Notebooks/'\n",
        "\n",
        "#response = requests.get(IMG_URL)\n",
        "#img_pil = Image.open(io.BytesIO(response.content))\n",
        "img_pil.save(folder + 'test.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZq-GfWZK5-Z"
      },
      "source": [
        "# Zastanówmy się nad modelem, którego będziemy używali. Wydrukujmy sobie jego architekturę.\n",
        "# Pamiętajcie, dla podstawowego CAMa, konieczna jest globalna warstwa uśredniająca (global average pooling, GAP)!\n",
        "# Każdy skonwolutowany obrazek musi odpowiadać tylko jednej wartości w pełni-połączonej ostatniej warstwie!\n",
        "# Sieci takie jak GoogleNet, ResNet, DenseNet mają wbudowanego GAPa na końcu, więc można na nich zastosować CAM bez żadnych modyfikacji.\n",
        "# Tak wyglądają ich architektury: https://neurohive.io/en/popular-networks/\n",
        "model_id = 2 # 1 = SqueezeNet, 2 = ResNet18, 3 = DenseNet161\n",
        "if model_id == 1:\n",
        "    net = models.squeezenet1_1(pretrained=True)\n",
        "    finalconv_name = 'features' # to ostatnia warstwa konwolucyjna modelu\n",
        "elif model_id == 2:\n",
        "    net = models.resnet18(pretrained=True)\n",
        "    finalconv_name = 'layer4'\n",
        "elif model_id == 3:\n",
        "    net = models.densenet161(pretrained=True)\n",
        "    finalconv_name = 'features'\n",
        "\n",
        "#print(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOf1Kto2ie1g"
      },
      "source": [
        "# Ustaw już wytrenowaną sieć do trybu ewaluacji\n",
        "net.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vnjg5ED6jaf6"
      },
      "source": [
        "# Teraz coś nietrywalnego. \"Zaczepimy się\" na konkretnej warstwie sieci. To znaczy, że nasz hak będzie zawierał wartości, które pojawiają się w \"zaczepionej\" warstwie. \n",
        "# Także kiedy zrobimy predykcję na obrazku testowym za pomocą naszego modelu, to hak będzie zawierał elementy przetworzonego przez sieć obrazka, które się tam pojawią.\n",
        "# Nazwa ostatniej warstwy sieci zależy od wybranego modelu. W komórce gdzie wybieraliśmy model, także zdefiniowaliśmy 'finalconv_name', którą Wam wcześniej sprawdziłam z architektury.\n",
        "# Bierzemy więc tu te pojedyncze wartości, do których GAP sprowadza każdy skonwolutowany obrazek.\n",
        "features_blobs = []\n",
        "def hook_feature(module, input, output):\n",
        "    features_blobs.append(output.data.cpu().numpy())\n",
        "\n",
        "net._modules.get(finalconv_name).register_forward_hook(hook_feature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w1dS3-_lEj1"
      },
      "source": [
        "# Tutaj wyciągamy wagi, które pojawiają się podczas klasyfikacji, przy softmaxie (po stronie GAPa, stąd 'params[-2]', czyli druga od końca)\n",
        "params = list(net.parameters())\n",
        "weight_softmax = np.squeeze(params[-2].data.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuSRKK5ylFSO"
      },
      "source": [
        "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
        "    size_upsample = (256, 256)\n",
        "    bz, nc, h, w = feature_conv.shape\n",
        "    output_cam = []\n",
        "    for idx in class_idx:\n",
        "        cam = weight_softmax[idx].dot(feature_conv.reshape((nc, h*w)))\n",
        "        cam = cam.reshape(h, w)\n",
        "        cam = cam - np.min(cam)\n",
        "        cam_img = cam / np.max(cam)\n",
        "        cam_img = np.uint8(255 * cam_img)\n",
        "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
        "    return output_cam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1ZgOZ6ylIOx"
      },
      "source": [
        "# Abu móc naszymi sieciami klasyfikować dowolny obrazek, musimy go najpierw trochę przeprocesować.\n",
        "# Mianowicie: (1) Zmienić wymiar do (224, 224), aby pasowało do wymiarów naszych sieci.\n",
        "# (2) Stransformować dane do formatu zwanego \"Tensorem\" używanym przez PyTorch.\n",
        "# (3) Znormalizować obrazek zgodnie ze średnią i odchyleniem standardowym danych treningowych w zestawie ImageNet (na których trenowane były wszystkie modele) .\n",
        "\n",
        "normalize = transforms.Normalize(\n",
        "   mean=[0.485, 0.456, 0.406],\n",
        "   std=[0.229, 0.224, 0.225])\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "   transforms.Resize((224,224)),\n",
        "   transforms.ToTensor(),\n",
        "   normalize])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAwwUVqQh6a4"
      },
      "source": [
        "img_tensor = preprocess(img_pil)\n",
        "img_variable = Variable(img_tensor.unsqueeze(0))\n",
        "\n",
        "# Teraz predykcja! Hak przyczepiony do ostatniej warstwy konwolucyjnej zapamięta do czego skolapsował obrazek.\n",
        "logit = net(img_variable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lQ76YRqgOFH"
      },
      "source": [
        "# Mamy predykcje dla wszystkich etykietek, ale teraz musimy (1) puścić to przez funkcję softmax, (2) znaleźć największą wartość (~prawdopodobieństwo)\n",
        "# (3) znaleźć do jakiej etykietki należy ta największa wartość\n",
        "\n",
        "# Pobierz listę kategorii ImageNetu:\n",
        "classes = {int(key):value for (key, value)\n",
        "          in requests.get(LABELS_URL).json().items()}\n",
        "\n",
        "# Puszczamy przez softmax:\n",
        "h_x = F.softmax(logit, dim=1).data.squeeze()\n",
        "\n",
        "# Sortujemy prawdopodobieństwa wraz z odpowiadającymi im kategoriami\n",
        "probs, idx = h_x.sort(0, True)\n",
        "probs = probs.numpy()\n",
        "idx = idx.numpy()\n",
        "\n",
        "# Output! (tutaj 5 etykietek z największymi prawdopodobieństwami)\n",
        "for i in range(0, 5):\n",
        "    print('{:.3f} -> {}'.format(probs[i], classes[idx[i]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_CkyQlfGzvc"
      },
      "source": [
        "# Wreszcie możemy wygenerować CAM dla dowolnej kategorii.\n",
        "# Zacznijmy od klasy z największym prawdopodobieństwem, czyli top1: idx[0] (bo sortowaliśmy względem prawdopodobieństw, pamiętacie?)\n",
        "CAMs = returnCAM(features_blobs[0], weight_softmax, [idx[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klnnqX1yG1tm"
      },
      "source": [
        "# Wydrukuj CAM\n",
        "print('output CAM.jpg for the top1 prediction: %s'%classes[idx[0]])\n",
        "img = cv2.imread(folder + 'test.jpg')\n",
        "height, width, _ = img.shape\n",
        "heatmap = cv2.applyColorMap(cv2.resize(CAMs[0],(width, height)), cv2.COLORMAP_JET)\n",
        "result = heatmap * 0.3 + img * 0.5\n",
        "cv2.imwrite(folder + 'CAM.jpg', result)\n",
        "cv2_imshow(result) # Colab i cv2.imshow() nie współpracują, więc musieliśmy zimportować patcha z cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbK8g57PS-6N"
      },
      "source": [
        "# Dla chętnych:\n",
        "\n",
        "## Zadania numeryczne:\n",
        "1. Metodą \"kopiuj-wklej\" stwórz funkcję, która za argument przyjmuje ścieżkę do obrazka z dysku, a zwraca mapę aktywacji odpowiedniej klasy.\n",
        "\n",
        "2. Wydrukuj i zastanów się nad kształtem kolejno: \n",
        "*   obrazka wprowadzanego do sieci\n",
        "*   outputem sieci\n",
        "*   rozmiarem ostatniej warstwy (po GAP)\n",
        "*   co funkcja CAM dokładnie robi? Czym jest 'weight_softmax[idx].dot(feature_conv.reshape((nc, h*w)))', dlaczego potem wynik jest reshape'owany do (h, w)? Czym są 'bz, nc, h, w'? Wydrukuj je wszystkie.\n",
        "*   co robi cv2.resize? Czemu go potrzebujemy?\n",
        "\n",
        "## Dyskusja:\n",
        "1. Zastosuj do kilku obrazków z internetu i zastanów się, co mapy mówią Ci o odpowiednich predykcjach sieci.\n",
        "2. Zastosuj do kilku obrazków z internetu z tej samej kategorii (np. różne psy, różne koty) i znów zastanów się, co mapy mówią Ci o odpowiednich predykcjach sieci.\n",
        "3. Bazując na klasyfikacji metod opisanej podczas części wykładowej, do jakiej kategorii należy CAM?\n",
        "  *   Jest zależny (model-specific) czy niezależny od modelu (model-agnostic)?\n",
        "  *   Daje lokalne czy globalne wyjaśnienia modelu?\n",
        "  *   Czy to (a) podejście surogatkowe? (b) metoda skupiająca się na analizie elementów składowych modelu? (c) metoda skupiająca się na analizie modelu po zaburzeniu danych wejściowych?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJsUfc7x_CiD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}